# ğŸ¤– A.D.A - Pocket AI

<p align="center">
  <img src="gui/assets/logo.png" alt="A.D.A Logo" width="120" height="120">
</p>

**A.D.A** (Advanced Digital Assistant) is a **fully local, privacy-focused AI assistant** for Windows. It combines a beautiful modern GUI with powerful voice control capabilitiesâ€”all running entirely on YOUR computer with no cloud dependency.

> ğŸ”’ **Your data stays on your machine.** No API keys required for core functionality. No subscriptions. No data collection.

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¤ **Voice Control** | Wake word detection ("Jarvis") with natural language commands |
| ğŸ’¬ **AI Chat** | Interactive chat with local LLMs via Ollama with streaming responses |
| ğŸ  **Smart Home** | Control TP-Link Kasa smart lights and plugs from the app |
| ğŸ“… **Planner** | Manage calendar events, alarms, and timers |
| ğŸ“° **Daily Briefing** | AI-curated news from Technology, Science, and Top Stories |
| ğŸŒ¤ï¸ **Weather** | Current weather and hourly forecast on your dashboard |
| ğŸ” **Web Search** | Search the web through voice or chat commands |
| ğŸ–¥ï¸ **System Monitor** | Real-time CPU and memory usage in the title bar |

---

## ğŸ“¸ Screenshots

*The application features a sleek Windows 11 Fluent Design aesthetic with dark mode support.*

---

## ğŸ“‹ Prerequisites

Before you begin, make sure you have:

### Required Software

| Software | Purpose | Installation |
|----------|---------|--------------|
| **Python 3.10+** | Runtime | [python.org](https://www.python.org/downloads/) |
| **Ollama** | Local AI model server | [ollama.com](https://ollama.com) |
| **NVIDIA GPU** (Recommended) | Faster AI inference | GPU with 4GB+ VRAM |

### Hardware Recommendations

- **Minimum**: 8GB RAM, any modern CPU
- **Recommended**: 16GB RAM, NVIDIA GPU with 6GB+ VRAM
- **Storage**: ~5GB for models and voice data

---

## ğŸš€ Quick Start Guide

Follow these steps to get A.D.A running on your system:

### Step 1: Clone the Repository

```bash
git clone https://github.com/your-username/pocket_ai.git
cd pocket_ai
```

### Step 2: Create a Virtual Environment (Recommended)

Using a virtual environment keeps your project dependencies isolated:

```bash
# Create a virtual environment
python -m venv venv

# Activate it (Windows)
venv\Scripts\activate

# Activate it (macOS/Linux)
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

> â±ï¸ **Note**: First installation may take 5-10 minutes as PyTorch and other large packages are downloaded.

### Step 4: Install Ollama & Download Models

1. Download and install Ollama from [ollama.com](https://ollama.com)
2. Open a terminal and pull the required model:

```bash
# Pull the responder model (1.7B parameters, ~1.5GB)
ollama pull qwen3:1.7b
```

3. Verify Ollama is running:
```bash
ollama list
```

You should see `qwen3:1.7b` in the list.

### Step 5: Run the Application

```bash
python main.py
```

ğŸ‰ **That's it!** A.D.A should now launch with a beautiful GUI.

---

## ğŸ™ï¸ Voice Assistant Setup

A.D.A includes Alexa-like voice control with wake word detection.

### How It Works

1. Say **"Jarvis"** to wake the assistant
2. Speak your command naturally
3. A.D.A processes your request and responds

### Example Voice Commands

| Command | What It Does |
|---------|--------------|
| *"Jarvis, turn on the office lights"* | Controls smart lights |
| *"Jarvis, set a timer for 10 minutes"* | Creates a countdown timer |
| *"Jarvis, what's on my schedule today?"* | Reads your calendar |
| *"Jarvis, search the web for Python tutorials"* | Performs web search |
| *"Jarvis, add buy groceries to my to-do list"* | Creates a task |

### Voice Configuration

Edit `config.py` to customize:

```python
# Change wake word (default: "jarvis")
WAKE_WORD = "jarvis"

# Adjust sensitivity (0.0-1.0, lower = less false positives)
WAKE_WORD_SENSITIVITY = 0.4

# Enable/disable voice assistant
VOICE_ASSISTANT_ENABLED = True
```

---

## âš™ï¸ Configuration

All configuration is centralized in `config.py`:

### AI Models

```python
# The main chat model (runs on Ollama)
RESPONDER_MODEL = "qwen3:1.7b"

# Ollama server URL
OLLAMA_URL = "http://localhost:11434/api"

# Path to the fine-tuned router model
LOCAL_ROUTER_PATH = "./merged_model"
```

### Text-to-Speech

```python
# Voice model (downloads automatically on first run)
TTS_VOICE_MODEL = "en_GB-northern_english_male-medium"
```

### Weather Location

The default location is New York City. To change it:

1. Open the app
2. Go to **Settings** tab
3. Enter your latitude and longitude

---

## ğŸ—ï¸ Project Architecture

```
pocket_ai/
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ config.py               # Centralized configuration
â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ core/                   # Backend logic
â”‚   â”œâ”€â”€ router.py           # FunctionGemma intent classifier
â”‚   â”œâ”€â”€ function_executor.py # Executes routed functions
â”‚   â”œâ”€â”€ voice_assistant.py  # Voice pipeline orchestrator
â”‚   â”œâ”€â”€ stt.py              # Speech-to-text with wake word
â”‚   â”œâ”€â”€ tts.py              # Piper text-to-speech
â”‚   â”œâ”€â”€ kasa_control.py     # Smart home device control
â”‚   â”œâ”€â”€ weather.py          # Open-Meteo weather API
â”‚   â”œâ”€â”€ news.py             # DuckDuckGo news + AI curation
â”‚   â”œâ”€â”€ tasks.py            # To-do list management
â”‚   â”œâ”€â”€ calendar_manager.py # Local calendar/events
â”‚   â”œâ”€â”€ history.py          # SQLite chat history
â”‚   â””â”€â”€ llm.py              # Ollama LLM interface
â”‚
â”œâ”€â”€ gui/                    # PySide6 GUI
â”‚   â”œâ”€â”€ app.py              # Main window setup
â”‚   â”œâ”€â”€ handlers.py         # Chat message handling
â”‚   â”œâ”€â”€ tabs/               # Individual tab screens
â”‚   â”‚   â”œâ”€â”€ dashboard.py    # Weather + status overview
â”‚   â”‚   â”œâ”€â”€ chat.py         # AI chat interface
â”‚   â”‚   â”œâ”€â”€ planner.py      # Calendar + tasks
â”‚   â”‚   â”œâ”€â”€ briefing.py     # AI news curation
â”‚   â”‚   â”œâ”€â”€ home_automation.py  # Smart device control
â”‚   â”‚   â””â”€â”€ settings.py     # App configuration
â”‚   â””â”€â”€ components/         # Reusable UI widgets
â”‚
â”œâ”€â”€ merged_model/           # Fine-tuned FunctionGemma router
â””â”€â”€ demo.py                 # Standalone voice assistant demo
```

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input â”‚â”€â”€â”€â”€â–¶â”‚ FunctionGemma   â”‚â”€â”€â”€â”€â–¶â”‚  Function   â”‚
â”‚  (Voice/Text)  â”‚     â”‚   Router         â”‚     â”‚  Executor   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                            â”‚                â”‚
       â–¼                                            â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kasa Lights â”‚                          â”‚   Calendar   â”‚   â”‚  Web Search  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ Qwen LLM     â”‚
                                          â”‚ (via Ollama) â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ Piper TTS    â”‚
                                          â”‚ (Voice Out)  â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **User speaks or types** a command
2. **FunctionGemma Router** (fine-tuned local AI) classifies intent
3. **Function Executor** runs the appropriate action
4. **Qwen LLM** generates a natural language response
5. **Piper TTS** speaks the response (if voice enabled)

---

## ğŸ  Smart Home Integration

A.D.A supports **TP-Link Kasa** smart devices:

### Supported Devices

- âœ… Smart bulbs (on/off, brightness, color)
- âœ… Smart plugs (on/off)
- âœ… Smart light strips

### Setup

1. Ensure your Kasa devices are on the same network as your computer
2. Open A.D.A and go to the **Home Automation** tab
3. Click **Refresh** to scan for devices
4. Control devices through the GUI or voice commands

### Voice Commands

```
"Turn on the living room lights"
"Set the bedroom lights to 50%"
"Turn off all lights"
"Change the office light to blue"
```

---

## ğŸ”§ Troubleshooting

### Common Issues

<details>
<summary><strong>âŒ Ollama connection refused</strong></summary>

**Problem**: The app can't connect to Ollama.

**Solution**:
1. Make sure Ollama is running: `ollama serve`
2. Check if the model is downloaded: `ollama list`
3. Verify the URL in `config.py` matches your setup

</details>

<details>
<summary><strong>âŒ CUDA/GPU not detected</strong></summary>

**Problem**: PyTorch is running on CPU instead of GPU.

**Solution**:
1. Install CUDA-compatible PyTorch:
   ```bash
   pip install torch --index-url https://download.pytorch.org/whl/cu121
   ```
2. Verify CUDA: `python -c "import torch; print(torch.cuda.is_available())"`

</details>

<details>
<summary><strong>âŒ Voice assistant not working</strong></summary>

**Problem**: Wake word isn't being detected.

**Solution**:
1. Check your microphone permissions
2. Ensure `realtimestt` is installed: `pip install realtimestt`
3. Try lowering `WAKE_WORD_SENSITIVITY` in `config.py`

</details>

<details>
<summary><strong>âŒ Smart devices not found</strong></summary>

**Problem**: Kasa devices don't appear in the app.

**Solution**:
1. Ensure devices are on the same WiFi network
2. Try the Kasa app first to verify devices work
3. Check firewall isn't blocking device discovery (UDP port 9999)

</details>

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how to get started:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `pytest tests/`
5. Submit a pull request

---

## ğŸ“œ License

This project is open source. See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.com/) - Local LLM inference
- [QFluentWidgets](https://github.com/zhiyiYo/PyQt-Fluent-Widgets) - Beautiful UI components
- [Piper TTS](https://github.com/rhasspy/piper) - Lightweight text-to-speech
- [python-kasa](https://github.com/python-kasa/python-kasa) - Kasa device control
- [RealTimeSTT](https://github.com/KoljaB/RealtimeSTT) - Speech recognition

---

<p align="center">
  Made with â¤ï¸ for local AI enthusiasts
</p>
